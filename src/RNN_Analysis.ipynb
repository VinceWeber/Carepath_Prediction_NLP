{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Module configuration\n",
    "#from py2neo import Graph #Database connection\n",
    "import neomodel\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neomodel import config\n",
    "\n",
    "neo4jServerAdress = \"172.19.144.105\"\n",
    "neo4jConnectionPort = 7687  #Connection to server bolt\n",
    "user= \"neo4j\" \n",
    "password= \"Mypassword%2023\"\n",
    "config.DATABASE_URL='bolt://' +user + ':' + password + '@' + neo4jServerAdress + ':' + str(neo4jConnectionPort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neomodel import (config, StructuredNode, StringProperty, IntegerProperty,DateTimeProperty,\n",
    "                    DateTimeFormatProperty,UniqueIdProperty, RelationshipTo,StructuredRel)\n",
    "\n",
    "config.DATABASE_URL='bolt://' +user + ':' + password + '@' + neo4jServerAdress + ':' + str(neo4jConnectionPort)\n",
    "\n",
    "#NIP\tJ_Parcours\tDateDebutActe\tDateFinActe\tUF\tService\tPhase_Parcours\tActivite\tDimension_Parcours\tRef_Acte\tid_Sequence\tType_Sequence\tid_sejour\n",
    "\n",
    "class FOLLOWED_BY(StructuredRel):\n",
    "    Nb_Days = IntegerProperty(index=True, default=0)\n",
    "    NIP=StringProperty(required=False)\n",
    "\n",
    "class Acte(StructuredNode):\n",
    "    Ref_Acte = StringProperty(required=True)\n",
    "    J_Parcours=IntegerProperty(required=True)\n",
    "    Duree = IntegerProperty(required=True)\n",
    "    UF = StringProperty(required=True)\n",
    "    #Service = StringProperty(required=True)\n",
    "    #Phase_Parcours =StringProperty(required=True)\n",
    "    #Activite =StringProperty(required=True)\n",
    "    #Dimension_Parcours = StringProperty(required=True)\n",
    "    Nombre_actes=IntegerProperty(required=False, default=1)     \n",
    "    Carepath = RelationshipTo('Acte', 'FOLLOWED_BY', model=FOLLOWED_BY)\n",
    "\n",
    "class Patient(StructuredNode):\n",
    "    NIP = StringProperty(unique_index=True, required=True)\n",
    "    J0 = StringProperty(required=True)\n",
    "    J_Parcours = IntegerProperty(required=False, default=0)\n",
    "    Carepath = RelationshipTo('Acte', 'BEGIN_CAREPATH_WITH', model=FOLLOWED_BY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NIP</th>\n",
       "      <th>J_Parcours</th>\n",
       "      <th>DateDebutActe</th>\n",
       "      <th>DateFinActe</th>\n",
       "      <th>UF</th>\n",
       "      <th>Service</th>\n",
       "      <th>Phase_Parcours</th>\n",
       "      <th>Activite</th>\n",
       "      <th>Dimension_Parcours</th>\n",
       "      <th>Ref_Acte</th>\n",
       "      <th>id_Sequence</th>\n",
       "      <th>Type_Sequence</th>\n",
       "      <th>id_sejour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N201900002</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-02 00:00:00.000</td>\n",
       "      <td>2019-01-02 00:00:00.000</td>\n",
       "      <td>8532</td>\n",
       "      <td>Médecine Nucléaire</td>\n",
       "      <td>Diagnostic</td>\n",
       "      <td>TEP</td>\n",
       "      <td>Soins</td>\n",
       "      <td>FTNTP2</td>\n",
       "      <td>12513</td>\n",
       "      <td>INIT_NEW</td>\n",
       "      <td>N1771659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N201900002</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-02 00:00:00.000</td>\n",
       "      <td>2019-01-02 00:00:00.000</td>\n",
       "      <td>8532</td>\n",
       "      <td>Médecine Nucléaire</td>\n",
       "      <td>Diagnostic</td>\n",
       "      <td>TEP</td>\n",
       "      <td>Soins</td>\n",
       "      <td>ZZQL016</td>\n",
       "      <td>12513</td>\n",
       "      <td>INIT_NEW</td>\n",
       "      <td>N1771659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N201900002</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-02 00:00:00.000</td>\n",
       "      <td>2019-01-02 00:00:00.000</td>\n",
       "      <td>1001</td>\n",
       "      <td>Médecine Nucléaire</td>\n",
       "      <td>Diagnostic</td>\n",
       "      <td>TEP</td>\n",
       "      <td>Soins</td>\n",
       "      <td>FTNTP2</td>\n",
       "      <td>12513</td>\n",
       "      <td>INIT_NEW</td>\n",
       "      <td>N160017801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N201900002</td>\n",
       "      <td>37</td>\n",
       "      <td>2019-02-08 00:00:00.000</td>\n",
       "      <td>2019-02-08 00:00:00.000</td>\n",
       "      <td>9050</td>\n",
       "      <td>Radiothérapie</td>\n",
       "      <td>Consultation</td>\n",
       "      <td>Consultations</td>\n",
       "      <td>Soins</td>\n",
       "      <td>CS</td>\n",
       "      <td>12513</td>\n",
       "      <td>INIT_NEW</td>\n",
       "      <td>N1791270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N201900002</td>\n",
       "      <td>37</td>\n",
       "      <td>2019-02-08 00:00:00.000</td>\n",
       "      <td>2019-02-08 00:00:00.000</td>\n",
       "      <td>9050</td>\n",
       "      <td>Radiothérapie</td>\n",
       "      <td>Consultation</td>\n",
       "      <td>Consultations</td>\n",
       "      <td>Soins</td>\n",
       "      <td>MCS</td>\n",
       "      <td>12513</td>\n",
       "      <td>INIT_NEW</td>\n",
       "      <td>N1791270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>N201900002</td>\n",
       "      <td>47</td>\n",
       "      <td>2019-02-18 00:00:00.000</td>\n",
       "      <td>2019-02-18 00:00:00.000</td>\n",
       "      <td>9052</td>\n",
       "      <td>Oncologie Medicale</td>\n",
       "      <td>Consultation</td>\n",
       "      <td>Consultations</td>\n",
       "      <td>Soins</td>\n",
       "      <td>CS</td>\n",
       "      <td>12513</td>\n",
       "      <td>INIT_NEW</td>\n",
       "      <td>N1794941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>N201900002</td>\n",
       "      <td>47</td>\n",
       "      <td>2019-02-18 00:00:00.000</td>\n",
       "      <td>2019-02-18 00:00:00.000</td>\n",
       "      <td>9052</td>\n",
       "      <td>Oncologie Medicale</td>\n",
       "      <td>Consultation</td>\n",
       "      <td>Consultations</td>\n",
       "      <td>Soins</td>\n",
       "      <td>MCS</td>\n",
       "      <td>12513</td>\n",
       "      <td>INIT_NEW</td>\n",
       "      <td>N1794941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>N201900002</td>\n",
       "      <td>50</td>\n",
       "      <td>2019-02-21 00:00:00.000</td>\n",
       "      <td>2019-02-21 00:00:00.000</td>\n",
       "      <td>9065</td>\n",
       "      <td>Imagerie Médicale</td>\n",
       "      <td>Diagnostic</td>\n",
       "      <td>IRM</td>\n",
       "      <td>Soins</td>\n",
       "      <td>LHQJ002</td>\n",
       "      <td>12513</td>\n",
       "      <td>INIT_NEW</td>\n",
       "      <td>N1796795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>N201900002</td>\n",
       "      <td>50</td>\n",
       "      <td>2019-02-21 00:00:00.000</td>\n",
       "      <td>2019-02-21 00:00:00.000</td>\n",
       "      <td>9065</td>\n",
       "      <td>Imagerie Médicale</td>\n",
       "      <td>Diagnostic</td>\n",
       "      <td>IRM</td>\n",
       "      <td>Soins</td>\n",
       "      <td>YYYY600</td>\n",
       "      <td>12513</td>\n",
       "      <td>INIT_NEW</td>\n",
       "      <td>N1796795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>N201900002</td>\n",
       "      <td>50</td>\n",
       "      <td>2019-02-21 00:00:00.000</td>\n",
       "      <td>2019-02-21 00:00:00.000</td>\n",
       "      <td>9065</td>\n",
       "      <td>Imagerie Médicale</td>\n",
       "      <td>Diagnostic</td>\n",
       "      <td>IRM</td>\n",
       "      <td>Soins</td>\n",
       "      <td>FTNIRM</td>\n",
       "      <td>12513</td>\n",
       "      <td>INIT_NEW</td>\n",
       "      <td>N1796795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>N201900006</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-02 00:00:00.000</td>\n",
       "      <td>2019-01-02 00:00:00.000</td>\n",
       "      <td>9050</td>\n",
       "      <td>Radiothérapie</td>\n",
       "      <td>Consultation</td>\n",
       "      <td>Consultations</td>\n",
       "      <td>Soins</td>\n",
       "      <td>CS</td>\n",
       "      <td>12532</td>\n",
       "      <td>INIT_NEW</td>\n",
       "      <td>N1771697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>N201900006</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-02 00:00:00.000</td>\n",
       "      <td>2019-01-02 00:00:00.000</td>\n",
       "      <td>9050</td>\n",
       "      <td>Radiothérapie</td>\n",
       "      <td>Consultation</td>\n",
       "      <td>Consultations</td>\n",
       "      <td>Soins</td>\n",
       "      <td>MCS</td>\n",
       "      <td>12532</td>\n",
       "      <td>INIT_NEW</td>\n",
       "      <td>N1771697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>N201900006</td>\n",
       "      <td>7</td>\n",
       "      <td>2019-01-09 00:00:00.000</td>\n",
       "      <td>2019-01-09 00:00:00.000</td>\n",
       "      <td>1938</td>\n",
       "      <td>Laboratoire</td>\n",
       "      <td>Diagnostic</td>\n",
       "      <td>Diagnostic</td>\n",
       "      <td>Soins</td>\n",
       "      <td>127</td>\n",
       "      <td>12532</td>\n",
       "      <td>INIT_NEW</td>\n",
       "      <td>N1775423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>N201900006</td>\n",
       "      <td>7</td>\n",
       "      <td>2019-01-09 00:00:00.000</td>\n",
       "      <td>2019-01-09 00:00:00.000</td>\n",
       "      <td>1938</td>\n",
       "      <td>Laboratoire</td>\n",
       "      <td>Diagnostic</td>\n",
       "      <td>Diagnostic</td>\n",
       "      <td>Soins</td>\n",
       "      <td>1127</td>\n",
       "      <td>12532</td>\n",
       "      <td>INIT_NEW</td>\n",
       "      <td>N1775423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>N201900006</td>\n",
       "      <td>7</td>\n",
       "      <td>2019-01-09 00:00:00.000</td>\n",
       "      <td>2019-01-09 00:00:00.000</td>\n",
       "      <td>1933</td>\n",
       "      <td>Laboratoire</td>\n",
       "      <td>Diagnostic</td>\n",
       "      <td>Diagnostic</td>\n",
       "      <td>Soins</td>\n",
       "      <td>514</td>\n",
       "      <td>12532</td>\n",
       "      <td>INIT_NEW</td>\n",
       "      <td>N1775423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>N201900006</td>\n",
       "      <td>7</td>\n",
       "      <td>2019-01-09 00:00:00.000</td>\n",
       "      <td>2019-01-09 00:00:00.000</td>\n",
       "      <td>9052</td>\n",
       "      <td>Oncologie Medicale</td>\n",
       "      <td>Consultation</td>\n",
       "      <td>Consultations</td>\n",
       "      <td>Soins</td>\n",
       "      <td>CS</td>\n",
       "      <td>12532</td>\n",
       "      <td>INIT_NEW</td>\n",
       "      <td>N1775423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>N201900006</td>\n",
       "      <td>7</td>\n",
       "      <td>2019-01-09 00:00:00.000</td>\n",
       "      <td>2019-01-09 00:00:00.000</td>\n",
       "      <td>9052</td>\n",
       "      <td>Oncologie Medicale</td>\n",
       "      <td>Consultation</td>\n",
       "      <td>Consultations</td>\n",
       "      <td>Soins</td>\n",
       "      <td>MCS</td>\n",
       "      <td>12532</td>\n",
       "      <td>INIT_NEW</td>\n",
       "      <td>N1775423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>N201900006</td>\n",
       "      <td>7</td>\n",
       "      <td>2019-01-09 00:00:00.000</td>\n",
       "      <td>2019-01-09 00:00:00.000</td>\n",
       "      <td>7172</td>\n",
       "      <td>Autre</td>\n",
       "      <td>Soins</td>\n",
       "      <td>INF</td>\n",
       "      <td>Soins</td>\n",
       "      <td>AMI</td>\n",
       "      <td>12532</td>\n",
       "      <td>INIT_NEW</td>\n",
       "      <td>N1775423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>N201900006</td>\n",
       "      <td>15</td>\n",
       "      <td>2019-01-17 00:00:00.000</td>\n",
       "      <td>2019-01-17 00:00:00.000</td>\n",
       "      <td>9057</td>\n",
       "      <td>Anesthésie</td>\n",
       "      <td>Consultation</td>\n",
       "      <td>Consultations</td>\n",
       "      <td>Soins Support</td>\n",
       "      <td>CS</td>\n",
       "      <td>12532</td>\n",
       "      <td>INIT_NEW</td>\n",
       "      <td>N1779618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>N201900006</td>\n",
       "      <td>15</td>\n",
       "      <td>2019-01-17 00:00:00.000</td>\n",
       "      <td>2019-01-17 00:00:00.000</td>\n",
       "      <td>9057</td>\n",
       "      <td>Anesthésie</td>\n",
       "      <td>Consultation</td>\n",
       "      <td>Consultations</td>\n",
       "      <td>Soins Support</td>\n",
       "      <td>MCS</td>\n",
       "      <td>12532</td>\n",
       "      <td>INIT_NEW</td>\n",
       "      <td>N1779618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>N201900006</td>\n",
       "      <td>23</td>\n",
       "      <td>2019-01-25 00:00:00.000</td>\n",
       "      <td>2019-01-25 00:00:00.000</td>\n",
       "      <td>9044</td>\n",
       "      <td>Chirurgie</td>\n",
       "      <td>Traitement</td>\n",
       "      <td>Ambulatoire</td>\n",
       "      <td>Soins</td>\n",
       "      <td>9097</td>\n",
       "      <td>12533</td>\n",
       "      <td>TRAIT</td>\n",
       "      <td>N1779875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>N201900006</td>\n",
       "      <td>23</td>\n",
       "      <td>2019-01-25 00:00:00.000</td>\n",
       "      <td>2019-01-25 00:00:00.000</td>\n",
       "      <td>9014</td>\n",
       "      <td>Chirurgie</td>\n",
       "      <td>TT ou Diag A def</td>\n",
       "      <td>Bloc Opératoire</td>\n",
       "      <td>Soins</td>\n",
       "      <td>QZQM001</td>\n",
       "      <td>12533</td>\n",
       "      <td>TRAIT</td>\n",
       "      <td>N1779875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>N201900006</td>\n",
       "      <td>23</td>\n",
       "      <td>2019-01-25 00:00:00.000</td>\n",
       "      <td>2019-01-25 00:00:00.000</td>\n",
       "      <td>9014</td>\n",
       "      <td>Chirurgie</td>\n",
       "      <td>TT ou Diag A def</td>\n",
       "      <td>Bloc Opératoire</td>\n",
       "      <td>Soins</td>\n",
       "      <td>EPLF002</td>\n",
       "      <td>12533</td>\n",
       "      <td>TRAIT</td>\n",
       "      <td>N1779875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           NIP  J_Parcours            DateDebutActe              DateFinActe  \\\n",
       "0   N201900002           0  2019-01-02 00:00:00.000  2019-01-02 00:00:00.000   \n",
       "1   N201900002           0  2019-01-02 00:00:00.000  2019-01-02 00:00:00.000   \n",
       "2   N201900002           0  2019-01-02 00:00:00.000  2019-01-02 00:00:00.000   \n",
       "3   N201900002          37  2019-02-08 00:00:00.000  2019-02-08 00:00:00.000   \n",
       "4   N201900002          37  2019-02-08 00:00:00.000  2019-02-08 00:00:00.000   \n",
       "5   N201900002          47  2019-02-18 00:00:00.000  2019-02-18 00:00:00.000   \n",
       "6   N201900002          47  2019-02-18 00:00:00.000  2019-02-18 00:00:00.000   \n",
       "7   N201900002          50  2019-02-21 00:00:00.000  2019-02-21 00:00:00.000   \n",
       "8   N201900002          50  2019-02-21 00:00:00.000  2019-02-21 00:00:00.000   \n",
       "9   N201900002          50  2019-02-21 00:00:00.000  2019-02-21 00:00:00.000   \n",
       "10  N201900006           0  2019-01-02 00:00:00.000  2019-01-02 00:00:00.000   \n",
       "11  N201900006           0  2019-01-02 00:00:00.000  2019-01-02 00:00:00.000   \n",
       "12  N201900006           7  2019-01-09 00:00:00.000  2019-01-09 00:00:00.000   \n",
       "13  N201900006           7  2019-01-09 00:00:00.000  2019-01-09 00:00:00.000   \n",
       "14  N201900006           7  2019-01-09 00:00:00.000  2019-01-09 00:00:00.000   \n",
       "15  N201900006           7  2019-01-09 00:00:00.000  2019-01-09 00:00:00.000   \n",
       "16  N201900006           7  2019-01-09 00:00:00.000  2019-01-09 00:00:00.000   \n",
       "17  N201900006           7  2019-01-09 00:00:00.000  2019-01-09 00:00:00.000   \n",
       "18  N201900006          15  2019-01-17 00:00:00.000  2019-01-17 00:00:00.000   \n",
       "19  N201900006          15  2019-01-17 00:00:00.000  2019-01-17 00:00:00.000   \n",
       "20  N201900006          23  2019-01-25 00:00:00.000  2019-01-25 00:00:00.000   \n",
       "21  N201900006          23  2019-01-25 00:00:00.000  2019-01-25 00:00:00.000   \n",
       "22  N201900006          23  2019-01-25 00:00:00.000  2019-01-25 00:00:00.000   \n",
       "\n",
       "      UF             Service    Phase_Parcours         Activite  \\\n",
       "0   8532  Médecine Nucléaire        Diagnostic              TEP   \n",
       "1   8532  Médecine Nucléaire        Diagnostic              TEP   \n",
       "2   1001  Médecine Nucléaire        Diagnostic              TEP   \n",
       "3   9050       Radiothérapie      Consultation    Consultations   \n",
       "4   9050       Radiothérapie      Consultation    Consultations   \n",
       "5   9052  Oncologie Medicale      Consultation    Consultations   \n",
       "6   9052  Oncologie Medicale      Consultation    Consultations   \n",
       "7   9065   Imagerie Médicale        Diagnostic              IRM   \n",
       "8   9065   Imagerie Médicale        Diagnostic              IRM   \n",
       "9   9065   Imagerie Médicale        Diagnostic              IRM   \n",
       "10  9050       Radiothérapie      Consultation    Consultations   \n",
       "11  9050       Radiothérapie      Consultation    Consultations   \n",
       "12  1938         Laboratoire        Diagnostic       Diagnostic   \n",
       "13  1938         Laboratoire        Diagnostic       Diagnostic   \n",
       "14  1933         Laboratoire        Diagnostic       Diagnostic   \n",
       "15  9052  Oncologie Medicale      Consultation    Consultations   \n",
       "16  9052  Oncologie Medicale      Consultation    Consultations   \n",
       "17  7172               Autre             Soins              INF   \n",
       "18  9057          Anesthésie      Consultation    Consultations   \n",
       "19  9057          Anesthésie      Consultation    Consultations   \n",
       "20  9044           Chirurgie        Traitement      Ambulatoire   \n",
       "21  9014           Chirurgie  TT ou Diag A def  Bloc Opératoire   \n",
       "22  9014           Chirurgie  TT ou Diag A def  Bloc Opératoire   \n",
       "\n",
       "   Dimension_Parcours Ref_Acte  id_Sequence Type_Sequence   id_sejour  \n",
       "0               Soins   FTNTP2        12513      INIT_NEW    N1771659  \n",
       "1               Soins  ZZQL016        12513      INIT_NEW    N1771659  \n",
       "2               Soins   FTNTP2        12513      INIT_NEW  N160017801  \n",
       "3               Soins       CS        12513      INIT_NEW    N1791270  \n",
       "4               Soins      MCS        12513      INIT_NEW    N1791270  \n",
       "5               Soins       CS        12513      INIT_NEW    N1794941  \n",
       "6               Soins      MCS        12513      INIT_NEW    N1794941  \n",
       "7               Soins  LHQJ002        12513      INIT_NEW    N1796795  \n",
       "8               Soins  YYYY600        12513      INIT_NEW    N1796795  \n",
       "9               Soins   FTNIRM        12513      INIT_NEW    N1796795  \n",
       "10              Soins       CS        12532      INIT_NEW    N1771697  \n",
       "11              Soins      MCS        12532      INIT_NEW    N1771697  \n",
       "12              Soins      127        12532      INIT_NEW    N1775423  \n",
       "13              Soins     1127        12532      INIT_NEW    N1775423  \n",
       "14              Soins      514        12532      INIT_NEW    N1775423  \n",
       "15              Soins       CS        12532      INIT_NEW    N1775423  \n",
       "16              Soins      MCS        12532      INIT_NEW    N1775423  \n",
       "17              Soins      AMI        12532      INIT_NEW    N1775423  \n",
       "18      Soins Support       CS        12532      INIT_NEW    N1779618  \n",
       "19      Soins Support      MCS        12532      INIT_NEW    N1779618  \n",
       "20              Soins     9097        12533         TRAIT    N1779875  \n",
       "21              Soins  QZQM001        12533         TRAIT    N1779875  \n",
       "22              Soins  EPLF002        12533         TRAIT    N1779875  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the filepath of the import csvfile\n",
    "file_path = r'..\\01_Datasets\\DL_Project_Dataset_Sample_V3.csv'\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path, sep=';')\n",
    "# Display the first few rows of the DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract information from a row\n",
    "date_format = '%Y-%m-%d %H:%M:%S.%f'\n",
    "\n",
    "def extract_data(row):\n",
    "    from datetime import datetime\n",
    "    acte = {\n",
    "        'Jp': row.get('J_Parcours', None),\n",
    "        'DDA': datetime.strptime(row.get('DateDebutActe', None), date_format),\n",
    "        'DDF': datetime.strptime(row.get('DateFinActe', None), date_format),\n",
    "        'Ref': row.get('Ref_Acte', None),\n",
    "        'NIP': row.get('NIP', None),\n",
    "        'UFname': str(row.get('UF', None)),\n",
    "        'service': row.get('Service', None),\n",
    "        'phase_parcours': row.get('Phase_Parcours', None).replace(\" \", \"\"),\n",
    "        'activite': row.get('Activite', None),\n",
    "        'dim_parcours': row.get('Dimension_Parcours', None),\n",
    "        'Sequence_id': row.get('id_Sequence', None),\n",
    "        'Sequence_Type': row.get('Type_Sequence', None),\n",
    "        'Sejour_id': row.get('id_sejour', None)\n",
    "    }\n",
    "\n",
    "    return acte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a query function\n",
    "def myquery(query, params=None):\n",
    "    from neomodel import db\n",
    "    results, meta = db.cypher_query(query, params, resolve_objects=True)\n",
    "    \n",
    "    \n",
    "    return results, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append to a node tuple\n",
    "\n",
    "def myappend(alist,value):\n",
    "    if not isinstance(alist, list):\n",
    "        newlist=[alist]\n",
    "    else:\n",
    "        newlist=alist\n",
    "    newlist.append(value)\n",
    "\n",
    "    return newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to create a new acte \n",
    "def create_acte(myActe):\n",
    "    new_acte=Acte(\n",
    "                    Ref_Acte = myActe['Ref'],\n",
    "                    Duree = int((myActe['DDF'] - myActe['DDA']).total_seconds()),\n",
    "                    J_Parcours = myActe['Jp'],\n",
    "                    UF = myActe['UFname'],\n",
    "                    #Service = myActe['service'],\n",
    "                    #Phase_Parcours = myActe['phase_parcours'],\n",
    "                    #Activite = myActe['activite'],\n",
    "                    #Dimension_Parcours = myActe['dim_parcours'],\n",
    "                ).save()\n",
    "    return new_acte\n",
    "\n",
    "def update_acte(myNodeActe, myNewActe):\n",
    "    \n",
    "    #Check if J_Parcours is th same between NodeActe and NewActe\n",
    "\n",
    "    if myNodeActe.J_Parcours==myNewActe['Jp']:\n",
    "        myNodeActe.Ref_Acte=myappend(myNodeActe.Ref_Acte,myNewActe['Ref'])\n",
    "        myNodeActe.UF=myappend(myNodeActe.UF,myNewActe['UFname'])\n",
    "        #myNodeActe.Service=myappend(myNodeActe.Service,myNewActe['service'])\n",
    "        #myNodeActe.Phase_Parcours=myappend(myNodeActe.Phase_Parcours,myNewActe['phase_parcours'])\n",
    "        #myNodeActe.Activite=myappend(myNodeActe.Activite,myNewActe['activite'])\n",
    "        #myNodeActe.Dimension_Parcours=myappend(myNodeActe.Dimension_Parcours,myNewActe['dim_parcours'])\n",
    "        myNodeActe.Nombre_actes=myNodeActe.Nombre_actes+1\n",
    "        myNodeActe.save()\n",
    "        \n",
    "    else:\n",
    "        raise (f\"Error in Updating Node {myNodeActe.id}, the new Acte doesn't have the same J parcours !\")\n",
    "\n",
    "    return myNodeActe\n",
    "\n",
    "\n",
    "def create_Startnode(myActe):\n",
    "    startNode=Patient(\n",
    "                    NIP = myActe['NIP'],\n",
    "                    J0 = myActe['DDA']\n",
    "                    ).save()\n",
    "    return startNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODELIZATION 5 : \n",
    "#NOEUDS : ACTES , DIFFERENTIATED BY PHASE PARCOURS.\n",
    "#RELATIONS : \n",
    "    # START : for the first acte\n",
    "    # ACTES REALIZED BY DAY\n",
    "\n",
    "#INITIALISATION   #CLEAR THE DATABASE\n",
    "query=\"MATCH (n) DETACH DELETE n\"\n",
    "myquery(query)\n",
    "\n",
    "Start=True\n",
    "output=True\n",
    "\n",
    "# Iterate over the rows of the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # Extract values from the DataFrame\n",
    "    myActe = extract_data(row)\n",
    "\n",
    "    if Start:\n",
    "        #Create a new acte\n",
    "        new_acte=create_acte(myActe)\n",
    "        Active_Node=new_acte\n",
    "        \n",
    "        #Create a start node\n",
    "        startNode=create_Startnode(myActe)\n",
    "\n",
    "        #LINK THE START NODE TO THE ACTES\n",
    "        startNode.Carepath.connect(new_acte)\n",
    "        Start=False\n",
    "\n",
    "        #SET THE START NODE AS THE PREVIOUS NODE\n",
    "        Previous_Node=startNode\n",
    "\n",
    "    else:\n",
    "        if oldActe['NIP']!=myActe['NIP']: #Check if we are dealing with the same patient\n",
    "            #Create a new acte\n",
    "            new_acte=create_acte(myActe)\n",
    "            \n",
    "            Active_Node=new_acte\n",
    "            \n",
    "            #Create a start node\n",
    "            startNode=create_Startnode(myActe)\n",
    "\n",
    "            #LINK THE START NODE TO THE ACTES\n",
    "            startNode.Carepath.connect(new_acte)\n",
    "            #SET THE START NODE AS THE PREVIOUS NODE\n",
    "            Previous_Node=startNode\n",
    "\n",
    "        else:            \n",
    "            #Check if we have to change the previous node\n",
    "            if myActe['Jp']!=oldActe['Jp']:\n",
    "                #Create a new acte\n",
    "                new_acte=create_acte(myActe)\n",
    "\n",
    "                Previous_Node=Active_Node\n",
    "                Active_Node=new_acte\n",
    "\n",
    "                #LINK THE ACTE TO THE PREVIOUS ONE\n",
    "                Previous_Node.Carepath.connect(new_acte, {'Nb_Days': myActe['Jp']-Previous_Node.J_Parcours ,'NIP': myActe['NIP'] })\n",
    "\n",
    "            else:\n",
    "                #update the active node\n",
    "                new_acte=update_acte(Active_Node,myActe)\n",
    "                #Active_Nodes.append(new_acte)\n",
    "\n",
    "    #Store the acte in a variable oldActe\n",
    "    oldActe=myActe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['Mygraph', 8, 6]], ['graphName', 'nodeCount', 'relationshipCount'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List exsiting graph in the database\n",
    "from neomodel import db\n",
    "query = \"\"\"\n",
    "CALL gds.graph.list()\n",
    "YIELD graphName, nodeCount, relationshipCount\n",
    "RETURN graphName, nodeCount, relationshipCount\n",
    "ORDER BY graphName ASC\n",
    "\"\"\"\n",
    "results = db.cypher_query(query)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#delete all existings graphs\n",
    "for graph in results[0]:\n",
    "    query = f\"\"\"\n",
    "            CALL gds.graph.drop('{graph[0]}') YIELD graphName;\n",
    "            \"\"\"\n",
    "    results = db.cypher_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Node Embedings\n",
    "\n",
    "#Create an in-Memory graph:\n",
    "query = \"\"\"\n",
    "CALL gds.graph.project(\n",
    "  'Mygraph',\n",
    "  'Acte',\n",
    "  'FOLLOWED_BY',\n",
    "  {\n",
    "    relationshipProperties: 'Nb_Days'\n",
    "  }\n",
    ")\n",
    "\"\"\"\n",
    "results = db.cypher_query(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need to specify a number of dimension :\n",
    "#CALL gds.node2vec.stream('Mygraph', {embeddingDimension: 2})\n",
    "#If you don't need to specify a number of dimension:\n",
    "#CALL gds.node2vec.stream('Mygraph')\n",
    "\n",
    "\n",
    "\n",
    "#run the node2vec algorithm:\n",
    "query = \"\"\"\n",
    "CALL gds.node2vec.stream('Mygraph', {embeddingDimension: 6})\n",
    "YIELD nodeId, embedding\n",
    "RETURN nodeId, embedding\n",
    "\"\"\"\n",
    "\n",
    "from neomodel import db\n",
    "results = db.cypher_query(query)\n",
    "\n",
    "nb_ebemdings_dimensions=len(results[0][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the result variable into a dict\n",
    "Dict_embedings = {}\n",
    "\n",
    "for entry in results[0]:\n",
    "    node_id = entry[0]\n",
    "    embedding = entry[1]\n",
    "    Dict_embedings[node_id] = {'Embedding': embedding}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET THE LIST OF PATIENT IN THE DATABASE\n",
    "\n",
    "query=\"\"\"MATCH (n:Patient) RETURN n.NIP\"\"\"\n",
    "list_of_NIPs = db.cypher_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['N201900002'], ['N201900006']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_NIPs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET THE LIST OF NODES_ID OF THE CAREPATH OF EACH PATIENT\n",
    "\n",
    "NIP_Carepath={}\n",
    "max_Carepath_lenght=0\n",
    "\n",
    "for i,nip in enumerate(list_of_NIPs[0],start=1):\n",
    "    \n",
    "    list_of_Nodes_ID=[]\n",
    "    Partial_Carepath=[]\n",
    "\n",
    "    query=f\"\"\"\n",
    "        MATCH (n:Acte)-[l:FOLLOWED_BY]->(m:Acte)\n",
    "        WHERE l.NIP='{nip[0]}'\n",
    "        RETURN id(n) AS NodeID, id(m) AS RelatedNodeID\n",
    "        ORDER BY NodeID asc\n",
    "        \"\"\"\n",
    "    list_of_Nodes_ID = db.cypher_query(query)\n",
    "\n",
    "    Carepath=[]\n",
    "    for j,relation in enumerate(list_of_Nodes_ID[0],start=0):\n",
    "        Carepath.append(relation[0])\n",
    "        lastnode=relation[1]\n",
    "\n",
    "        #Partial Carepath\n",
    "        Partial_Carepath.append(Carepath.copy()) \n",
    "\n",
    "    #construct the list\n",
    "    Carepath.append(lastnode)\n",
    "    #Partial Carepath\n",
    "    Partial_Carepath.append(Carepath.copy()) \n",
    "\n",
    "\n",
    "    #Add the carepath to the dict\n",
    "    NIP_Carepath[i]={'NIP' : nip[0], 'Carepath' : Carepath, 'SampleCareMatrix' : Partial_Carepath}\n",
    "    \n",
    "    #udpate the max Carepath lenght\n",
    "    if max_Carepath_lenght<len(Carepath) : max_Carepath_lenght=len(Carepath)\n",
    "\n",
    "#NIP_Carepath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'NIP': 'N201900002',\n",
       "  'Carepath': [140, 142, 143, 144],\n",
       "  'SampleCareMatrix': [[140],\n",
       "   [140, 142],\n",
       "   [140, 142, 143],\n",
       "   [140, 142, 143, 144]]},\n",
       " 2: {'NIP': 'N201900006',\n",
       "  'Carepath': [145, 147, 148, 149],\n",
       "  'SampleCareMatrix': [[145],\n",
       "   [145, 147],\n",
       "   [145, 147, 148],\n",
       "   [145, 147, 148, 149]]}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NIP_Carepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct the SampleMatrix to a determined dimension and fill zeros at the left when dimension isn't enought\n",
    "\n",
    "#determine the size of X (nb of columns)\n",
    "#Maximum lenght of carepath in the database\n",
    "nb_columns=max_Carepath_lenght\n",
    "#nb_columns=2\n",
    "\n",
    "#or a definite value\n",
    "#nb_columns=2\n",
    "\n",
    "#Croop the matrix to the number of column defined\n",
    "for key, value in NIP_Carepath.items():\n",
    "    value['SampleCareMatrix'] = [sample[-nb_columns:] for sample in value['SampleCareMatrix']]\n",
    "\n",
    "#Add zeros at the left when the size of the sampleCareMatrix is less than to the nb of column defined\n",
    "for key, value in NIP_Carepath.items():\n",
    "    for sample in value['SampleCareMatrix']:\n",
    "        while len(sample) < nb_columns:\n",
    "            sample.insert(0, 0)\n",
    "\n",
    "#NIP_Carepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'NIP': 'N201900002',\n",
       "  'Carepath': [140, 142, 143, 144],\n",
       "  'SampleCareMatrix': [[0, 0, 0, 140],\n",
       "   [0, 0, 140, 142],\n",
       "   [0, 140, 142, 143],\n",
       "   [140, 142, 143, 144]]},\n",
       " 2: {'NIP': 'N201900006',\n",
       "  'Carepath': [145, 147, 148, 149],\n",
       "  'SampleCareMatrix': [[0, 0, 0, 145],\n",
       "   [0, 0, 145, 147],\n",
       "   [0, 145, 147, 148],\n",
       "   [145, 147, 148, 149]]}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NIP_Carepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dict_embedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dict_embedings[4907]['Embedding']\n",
    "#Dict_embedings[NodeId]['Embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_dim=nb_ebemdings_dimensions\n",
    "\n",
    "#Create a SampleCareTensor from the SampleCareMatrix where NodeIds are replaced by their embedings\n",
    "for key, value in NIP_Carepath.items():\n",
    "    value['SampleCareTensor'] = []\n",
    "    for CM_Index,NodeIds_List in enumerate(value['SampleCareMatrix'],start=0):\n",
    "        my_Embedings=[]\n",
    "        for NodesIds_index,val_NodeId in enumerate(NodeIds_List,start=0):\n",
    "            if val_NodeId==0:\n",
    "                my_Embedings.append([0] * nb_dim)\n",
    "            else:\n",
    "                my_Embedings.append(Dict_embedings[val_NodeId]['Embedding'])\n",
    "        value['SampleCareTensor'].append(my_Embedings)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#nb of columns is defined in a previous cell dedicated to #Construct the SampleMatrix\n",
    "\n",
    "G_CP_matrix = np.empty((0, nb_columns))  # Initialize an empty matrix\n",
    "CP_matrix = np.empty((0, nb_columns))  # Initialize an empty matrix\n",
    "\n",
    "for index in NIP_Carepath : \n",
    "    My_CP_Vector = NIP_Carepath[index]['SampleCareTensor']\n",
    "    CP_matrix = np.empty((0, nb_columns))  # Initialize an empty matrix\n",
    "\n",
    "    for CP_item in My_CP_Vector:\n",
    "        V = []\n",
    "        for embedding in CP_item:\n",
    "            V.append(np.transpose(embedding))\n",
    "\n",
    "        matrix = np.column_stack(V)\n",
    "        CP_matrix = np.vstack((CP_matrix, matrix))\n",
    "\n",
    "    G_CP_matrix = np.vstack((G_CP_matrix, CP_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (38, 3)\n",
      "X_test shape: (10, 3)\n",
      "Y_train shape: (38,)\n",
      "Y_test shape: (10,)\n"
     ]
    }
   ],
   "source": [
    "# CREATE X, Y TRAIN AND TEST SAMPLES\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Scale the features to have values between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "G_scaled = scaler.fit_transform(G_CP_matrix)\n",
    "\n",
    "\n",
    "# G_CP_matrix contains features (X) and labels (Y)\n",
    "X = G_scaled[:, :-1]  # Extract all columns except the last one from G_CP_matrix \n",
    "Y = G_scaled[:, -1]   # Extract the last column from G_CP_matrix\n",
    "\n",
    "# Split data into training and testing sets for both features and labels\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verify shapes of the datasets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"Y_train shape:\", Y_train.shape)\n",
    "print(\"Y_test shape:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's construct a function Vec_to_Node in order to construct the prevision of carepath.\n",
    "\n",
    "#function Vec_2_node\n",
    "def Vec_2_node(query_vector, embeddings):\n",
    "    closest_node_id = None\n",
    "    closest_distance = float('inf')\n",
    "    \n",
    "    for node_id, node_embedding in embeddings.items():\n",
    "        embedding_vector = node_embedding['Embedding']\n",
    "        distance = np.linalg.norm(query_vector - embedding_vector)  # Euclidean distance\n",
    "        if distance < closest_distance:\n",
    "            closest_distance = distance\n",
    "            closest_node_id = node_id\n",
    "            \n",
    "    return closest_node_id\n",
    "\n",
    "# Example usage\n",
    "#query_vector = np.array([0.5, 0.3, -0.1])  # Example vector you want to find the node for\n",
    "#closest_node_id = Vec_2_node(query_vector, Dict_embedings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALTERNATIVE\n",
    "#CONSTRUCT THE X-Y Tensor BY CONCATENATE SamplesCareTensors in rows.\n",
    "import numpy as np\n",
    "\n",
    "# Extract SampleCareTensors from the dictionary\n",
    "sample_tensors = [NIP_Carepath[key]['SampleCareTensor'] for key in NIP_Carepath]\n",
    "# Concatenate the tensors along the first axis\n",
    "XY_tensor = np.concatenate(sample_tensors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 4, 6)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [-0.01776358, -0.01770933, -0.06256501,  0.00850261,  0.02232497,\n",
       "         0.01361495],\n",
       "       [-0.01595206, -0.0755004 ,  0.07721831,  0.07664921,  0.06532622,\n",
       "        -0.04659249]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY_tensor[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71783096, 0.51695755, 0.51127766])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40171335241526923"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_vector=XY_tensor[3,1]\n",
    "Vec_2_node(query_vector, Dict_embedings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEEP LEARNING ANALYSIS\n",
    "\n",
    "When implementing your CNN for process log prediction, consider the following aspects:\n",
    "    Data Representation: How will you represent your process log data as input to the CNN? This could involve encoding categorical variables, representing sequences of events, or using embeddings.\n",
    "    Model Architecture: Design the architecture of your CNN, considering factors such as the number of convolutional layers, kernel sizes, dilation rates (for TCNs), pooling layers, and the overall network architecture.\n",
    "    Training Procedure: Determine how you will train your CNN, including the loss function, optimization algorithm, and any regularization techniques.\n",
    "    Evaluation Metrics: Decide on appropriate evaluation metrics for assessing the performance of your CNN model on the process log prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        #Defining the layers\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Initializing hidden state for first input using method defined below\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        hidden = hidden.to(device)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_ebemdings_dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter definition :\n",
    "\n",
    "inputsize  =  nb_ebemdings_dimensions\n",
    "outputsize = nb_ebemdings_dimensions\n",
    "hiddendim = 2\n",
    "nlayers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting sub-tensor\n",
    "X = XY_tensor[:, 0:(max_Carepath_lenght-1), :]\n",
    "Y = XY_tensor[:, 1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of input_seq and output_seq\n",
    "input_seq = torch.from_numpy(X).to(torch.float32)\n",
    "target_seq = torch.Tensor(Y).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 4, 6)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with hyperparameters\n",
    "model = Model(input_size=inputsize, output_size=outputsize, hidden_dim=hiddendim, n_layers=nlayers)\n",
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define hyperparameters\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (24) to match target batch_size (144).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m input_seq \u001b[38;5;241m=\u001b[39m input_seq\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      5\u001b[0m output, hidden \u001b[38;5;241m=\u001b[39m model(input_seq)\n\u001b[1;32m----> 6\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_seq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m# Does backpropagation and calculates gradients\u001b[39;00m\n\u001b[0;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m# Updates the weights accordingly\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\DL_Project2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\DL_Project2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\DL_Project2\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\DL_Project2\\lib\\site-packages\\torch\\nn\\functional.py:3053\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3052\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (24) to match target batch_size (144)."
     ]
    }
   ],
   "source": [
    "# Training Run\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "    input_seq = input_seq.to(device)\n",
    "    output, hidden = model(input_seq)\n",
    "    loss = criterion(output, target_seq.view(-1).long())\n",
    "    loss.backward() # Does backpropagation and calculates gradients\n",
    "    optimizer.step() # Updates the weights accordingly\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
